{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhWRc1MdZyJOEF2gRa3wk3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q numpy\n",
        "import numpy as np\n",
        "import random\n",
        "import copy"
      ],
      "metadata": {
        "id": "WTil332M_z2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0KBwxb08W4c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class TicTacToe:\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.board = np.zeros((3, 3), dtype=int)\n",
        "        self.current_player = 1\n",
        "        return self._get_state()\n",
        "\n",
        "    def _get_state(self):\n",
        "        return tuple(self.board.reshape(-1))\n",
        "\n",
        "    def available_actions(self):\n",
        "        return list(zip(*np.where(self.board == 0)))\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.board[action] != 0:\n",
        "            raise ValueError(\"Invalid move!\")\n",
        "        self.board[action] = self.current_player\n",
        "        winner = self._check_winner()\n",
        "        done = winner is not None or not self.available_actions()\n",
        "        reward = 0\n",
        "        if done:\n",
        "            reward = 1 if winner == self.current_player else 0\n",
        "        self.current_player *= -1\n",
        "        return self._get_state(), reward, done\n",
        "\n",
        "    def _check_winner(self):\n",
        "        for i in range(3):\n",
        "            if abs(sum(self.board[i, :])) == 3:\n",
        "                return np.sign(sum(self.board[i, :]))\n",
        "            if abs(sum(self.board[:, i])) == 3:\n",
        "                return np.sign(sum(self.board[:, i]))\n",
        "        diag1 = sum([self.board[i, i] for i in range(3)])\n",
        "        diag2 = sum([self.board[i, 2 - i] for i in range(3)])\n",
        "        if abs(diag1) == 3:\n",
        "            return np.sign(diag1)\n",
        "        if abs(diag2) == 3:\n",
        "            return np.sign(diag2)\n",
        "        return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# td_agent.py\n",
        "\n",
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "class TDAgent:\n",
        "    def __init__(self, alpha=0.1, gamma=0.9, epsilon=0.1):\n",
        "        self.V = defaultdict(float)\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def choose_action(self, env):\n",
        "        actions = env.available_actions()\n",
        "        if random.random() < self.epsilon:\n",
        "            return random.choice(actions)\n",
        "        best_value = -float('inf')\n",
        "        best_action = None\n",
        "        for action in actions:\n",
        "            temp_env = TicTacToe()\n",
        "            temp_env.board = env.board.copy()\n",
        "            temp_env.current_player = env.current_player\n",
        "            state, _, _ = temp_env.step(action)\n",
        "            value = self.V[state]\n",
        "            if value > best_value:\n",
        "                best_value = value\n",
        "                best_action = action\n",
        "        return best_action\n",
        "\n",
        "    def learn(self, state, reward, next_state, done):\n",
        "        target = reward if done else reward + self.gamma * self.V[next_state]\n",
        "        self.V[state] += self.alpha * (target - self.V[state])\n"
      ],
      "metadata": {
        "id": "wiNmcpLQ8Xu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "\n",
        "class MCTSNode:\n",
        "    def __init__(self, state, parent=None):\n",
        "        self.state = state\n",
        "        self.parent = parent\n",
        "        self.children = {}\n",
        "        self.visits = 0\n",
        "        self.value = 0.0\n",
        "\n",
        "    def is_leaf(self):\n",
        "        return len(self.children) == 0\n",
        "\n",
        "class MCTSAgent:\n",
        "    def __init__(self, simulations=50, exploration=1.4):\n",
        "        self.simulations = simulations\n",
        "        self.exploration = exploration\n",
        "\n",
        "    def ucb_score(self, parent, child):\n",
        "        if child.visits == 0:\n",
        "            return float('inf')\n",
        "        return child.value / child.visits + self.exploration * math.sqrt(\n",
        "            math.log(parent.visits) / child.visits\n",
        "        )\n",
        "\n",
        "    def select(self, node):\n",
        "        while not node.is_leaf():\n",
        "            node = max(node.children.values(), key=lambda n: self.ucb_score(node, n))\n",
        "        return node\n",
        "\n",
        "    def expand(self, node):\n",
        "        env = self._rebuild_env(node)\n",
        "        for action in env.available_actions():\n",
        "            next_env = self._rebuild_env(node)\n",
        "            next_state, _, _ = next_env.step(action)\n",
        "            if action not in node.children:\n",
        "                node.children[action] = MCTSNode(next_state, parent=node)\n",
        "\n",
        "    def simulate(self, node):\n",
        "        env = self._rebuild_env(node)\n",
        "        current_player = env.current_player\n",
        "        done = False\n",
        "        reward = 0\n",
        "        while not done:\n",
        "            actions = env.available_actions()\n",
        "            action = random.choice(actions)\n",
        "            _, reward, done = env.step(action)\n",
        "        return reward if env.current_player != current_player else -reward\n",
        "\n",
        "    def backpropagate(self, node, reward):\n",
        "        while node:\n",
        "            node.visits += 1\n",
        "            node.value += reward\n",
        "            reward = -reward\n",
        "            node = node.parent\n",
        "\n",
        "    def _rebuild_env(self, node):\n",
        "        env = TicTacToe()\n",
        "        env.board = np.array(node.state).reshape(3, 3)\n",
        "        env.current_player = 1\n",
        "        return env\n",
        "\n",
        "    def choose_action(self, env):\n",
        "        actions = env.available_actions()\n",
        "        for in actions(self.simulations):\n",
        "            node = self.select(actions)\n",
        "            self.expand(node)\n",
        "            reward = self.simulate(node)\n",
        "            self.backpropagate(node, reward)\n",
        "        best_action = max(actions.children.items(), key=lambda item: item[1].visits)[0]\n",
        "        return best_action\n",
        "\n",
        "# main.py\n",
        "\n",
        "\n",
        "\n",
        "env = TicTacToe()\n",
        "td_agent = TDAgent()\n",
        "mcts_agent = MCTSAgent()\n",
        "\n",
        "EPISODES = 1000\n",
        "td_wins = 0\n",
        "mcts_wins = 0\n",
        "\n",
        "for episode in range(EPISODES):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        if env.current_player == 1:\n",
        "            action = td_agent.choose_action(env) if first_player == \"td\" else mcts_agent.choose_action(env)\n",
        "        else:\n",
        "            action = mcts_agent.choose_action(env) if first_player == \"td\" else td_agent.choose_action(env)\n",
        "\n",
        "        if action is None:\n",
        "            break  # No actions left; game must be done\n",
        "\n",
        "        next_state, reward, done = env.step(action)\n",
        "\n",
        "        # Optional: agent learning\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "    # Score tracking:\n",
        "    if done:\n",
        "        winner = env.get_winner()  # <-- make sure this exists\n",
        "        if winner == 1 and first_player == \"td\":\n",
        "            td_wins += 1\n",
        "        elif winner == 1 and first_player == \"mcts\":\n",
        "            mcts_wins += 1\n",
        "\n",
        "\n",
        "\n",
        "    if reward == 1:\n",
        "        if env.current_player == -1 and first_player == \"td\":\n",
        "            td_wins += 1\n",
        "        elif env.current_player == -1 and first_player == \"mcts\":\n",
        "            mcts_wins += 1\n",
        "def get_winner(self):\n",
        "    if self.check_win(1):\n",
        "        return 1\n",
        "    elif self.check_win(-1):\n",
        "        return -1\n",
        "    else:\n",
        "        return 0  # draw or not finished\n",
        "\n",
        "print(f\"TD wins: {td_wins}\")\n",
        "print(f\"MCTS wins: {mcts_wins}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "Uj-7m4Ex8XxW",
        "outputId": "7bf20ff9-1a38-450f-b3de-d13606291c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'list' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-22-1174177488.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_player\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtd_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfirst_player\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"td\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmcts_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcts_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfirst_player\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"td\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtd_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-22-1174177488.py\u001b[0m in \u001b[0;36mchoose_action\u001b[0;34m(self, env)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mchoose_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavailable_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "c_McCJcy8X0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "umS4xXN-8X29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Ti98Auy8X5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aShLWdFm8X8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xPNuTkTX8X-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DsZXFbCf8YBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-7Qt302L8YER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lznhys838YG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qYwOWF868YJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SCFT6E9y8YMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7cRjSULA8YPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dZdTpH0_8YSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dk8Ax0ec8YUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YoRf20BZ8YXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zp9gaHM68YaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wF5BrSuj8Yc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xOXwMvqM8Yfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H4ls4zdP8YjP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}